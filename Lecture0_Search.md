# ğŸ§  CS50 AI - Lecture 0: Search

This lecture explores the foundational ideas of **search in Artificial Intelligence** â€” how an agent finds its way from an initial state to a goal state using different strategies

---

## ğŸ“Œ What is Artificial Intelligence?

Artificial Intelligence (AI) includes a wide range of techniques where computers simulate intelligent behavior.

### Examples:
- ğŸ“· Face recognition (e.g., social media)
- â™Ÿï¸ Game-playing (e.g., chess)
- ğŸ¤ Voice assistants (e.g., Siri, Alexa)

### Key Areas Covered in the Course:
- **Search** â€“ Finding solutions to problems (like maps, games)
- **Knowledge** â€“ Representing and reasoning from facts
- **Uncertainty** â€“ Using probabilities in uncertain situations
- **Optimization** â€“ Finding the best solution, not just any
- **Learning** â€“ Improving performance over time (e.g., spam filters)
- **Neural Networks** â€“ Brain-inspired models for pattern recognition
- **Language** â€“ Understanding and producing human language

---

## ğŸ” Search Fundamentals

### Search Problem Components

| Concept            | Meaning                            | Example                         |
|--------------------|------------------------------------|----------------------------------|
| **Agent**          | Entity making decisions            | A car navigating a map           |
| **State**          | Situation or configuration         | Puzzle layout                    |
| **Initial State**  | Where we start                     | Current location                 |
| **Actions(s)**     | What can be done                   | Slide tiles, move forward        |
| **Transition Model** | What happens after action        | New puzzle layout                |
| **Goal Test**      | Has the goal been reached?         | Destination reached              |
| **Path Cost**      | How costly the path is             | Shortest route                   |

---

## ğŸ§± Nodes and Frontier

- A **Node** stores the current state, its parent, the action that led there, and the path cost.
- The **Frontier** manages which nodes to explore next.
- The algorithm explores nodes from the frontier, expands them, and adds new nodes until it reaches the goal.

---

## ğŸ”„ Search Algorithms

### 1. Depth-First Search (DFS)
- ğŸ“¦ Uses: **Stack (LIFO)**
- Explores one path as deep as possible before backtracking.

**Pros:**
- Fast if lucky
- Low memory usage

**Cons:**
- Not optimal
- May go in wrong direction forever

**Real-World Use:** Game trees, puzzles

---

### 2. Breadth-First Search (BFS)
- ğŸ“¦ Uses: **Queue (FIFO)**
- Explores all nodes at the current depth before moving deeper.

**Pros:**
- Guarantees shortest path
- Complete

**Cons:**
- Memory intensive

**Real-World Use:** Shortest path in maps

---

### 3. Greedy Best-First Search
- Uses a **heuristic function h(n)** to estimate the cost to the goal.
- Always chooses the node closest to the goal based on estimate.

**Pros:**
- Fast with good heuristic

**Cons:**
- Not optimal
- Can go down bad paths

**Real-World Use:** Mazes, navigation AI

---

### 4. A* Search
- Combines:
  - `g(n)` = actual cost so far
  - `h(n)` = estimated cost to goal
  - `f(n) = g(n) + h(n)`

**Pros:**
- Optimal if `h(n)` is admissible and consistent
- Efficient with good heuristic

**Cons:**
- High memory usage

**Real-World Use:** GPS, robotics, pathfinding

---

## ğŸ® Adversarial Search

Used when an agent must make decisions against an **opponent**, such as in games like Tic Tac Toe or Chess.

---

### Minimax Algorithm

- Alternates between **maximizer** and **minimizer**.
- Assigns:
  - +1 if maximizer wins
  - -1 if minimizer wins
  - 0 if tie
- Explores all possible game outcomes recursively.
- Chooses action that maximizes or minimizes the expected value.

**Real-World Use:** Board games, decision-making AI

---

### Alpha-Beta Pruning

- Optimizes minimax by pruning branches that wonâ€™t affect the final decision.
- Saves time by ignoring obviously bad options.

**Real-World Use:** Chess engines, large game trees

---

### Depth-Limited Minimax

- Only explores a limited depth.
- Uses an **evaluation function** to estimate state utility.
- Commonly used when game trees are too large (e.g., Chess, Go).

**Real-World Use:** Advanced board games with large possibilities

---

## ğŸ“Š Summary Table of Search Algorithms

| Algorithm               | Type         | Optimal | Speed               | Memory Usage | Heuristic Used     | Complete | Real-World Use                      |
|-------------------------|--------------|---------|---------------------|----------------|--------------------|----------|-------------------------------------|
| Depth-First Search      | Uninformed   | âŒ      | âš¡ Fast (best case)  | ğŸ§  Low         | âŒ                 | âŒ       | Game trees, puzzles                 |
| Breadth-First Search    | Uninformed   | âœ…      | ğŸ¢ Slower            | ğŸ§  High        | âŒ                 | âœ…       | Maps, shortest path problems        |
| Greedy Best-First       | Informed     | âŒ      | âš¡ Fast              | ğŸ§  Medium      | âœ…                 | âŒ       | Mazes, AI navigation                |
| A* Search               | Informed     | âœ…      | âš¡ Fast (good h)     | ğŸ§  High        | âœ…                 | âœ…       | GPS, robotics, games                |
| Minimax                 | Adversarial  | âœ… (small games) | ğŸŒ Slow     | ğŸ§  High        | âŒ                 | âœ…       | Tic Tac Toe, board games            |
| Alpha-Beta Pruning      | Adversarial  | âœ…      | âš¡ Faster than Minimax | ğŸ§  Medium   | âŒ                 | âœ…       | Chess, complex board games          |
| Depth-Limited Minimax   | Adversarial  | âŒ (estimates) | âš¡ Scalable     | ğŸ§  Medium      | âœ… (evaluation)    | âŒ       | Chess, Go, Checkers                 |

---

âœ… **End of Lecture 0 Notes**
